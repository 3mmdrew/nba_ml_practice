{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same exact problem as in nn_eperimenting but down with the Python Pytorch API\n",
    "\n",
    "- plus exponents and division not included in the main class of nn_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x1 = torch.Tensor([2.0]).double() ; x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double() ; x2.requires_grad = True\n",
    "w1 = torch.Tensor([-3.0]).double() ; w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double() ; w2.requires_grad = True\n",
    "\n",
    "b = torch.Tensor([6.88137358735]).double() ; b.requires_grad = True\n",
    "n = x1*w1 + x2*w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are just n-dimensional arrays of scalars..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[1,2,3],[3,4,5]]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".double() is to cast to a double and make the default 'float32' dtype become a 'float64' which Python will recognise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n",
      "------\n",
      "x2 0.5000001283844369\n",
      "w2 0.0\n",
      "x1 -1.5000003851533106\n",
      "w1 1.0000002567688737\n"
     ]
    }
   ],
   "source": [
    "print(o.data.item())\n",
    "o.backward()\n",
    "print('------')\n",
    "print('x2',x2.grad.item())\n",
    "print('w2',w2.grad.item())\n",
    "print('x1',x1.grad.item())\n",
    "print('w1',w1.grad.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".item() will output the individual number in PyTorch / otherwise .data, .grad will output larger statements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64c8547dd3f5b35e0c1e90f347e298d90b955a7b7b375dec677bec5b0a272829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
